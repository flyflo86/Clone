{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Behavioral Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keras\n",
    "from os.path import split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Preprocessing DATA\n",
    "batch_size_generator=128\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "#    cv2.imshow('image',image)\n",
    "#    cv2.waitKey(0)\n",
    "#    cv2.destroyAllWindows()\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "\n",
    "def prepro_image(image):\n",
    "    # cropping the image (upper and lower part don't contain important information)\n",
    "    adapted_image = image[50:140,:,:]\n",
    "    # apply subtle blur\n",
    "    adapted_image = cv2.GaussianBlur(adapted_image, (3,3), 0)\n",
    "    # Scaling to shape input of model is expecting (200x66)\n",
    "    adapted_image = cv2.resize(adapted_image,(200, 66), interpolation = cv2.INTER_AREA)\n",
    "    # Converting to YUV \n",
    "    adapted_image = cv2.cvtColor(adapted_image, cv2.COLOR_RGB2YUV)\n",
    "    return adapted_image\n",
    "\n",
    "\n",
    "#*****************************DATA PREPARATION*******************************************\n",
    "lines=[]\n",
    "#with open('../data/driving_log.csv') as file:\n",
    "with open('data_downloaded/driving_log.csv') as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "#Current Path\n",
    "def current_path(image_direction, line):\n",
    "    source_path = line[image_direction]\n",
    "    filename = split(source_path)[1]\n",
    "    current_path = './data_downloaded/IMG/' + filename\n",
    "#   current_path = '../data/IMG/' + filename\n",
    "    return current_path     \n",
    "\n",
    "def generate_training_path_sources(lines):\n",
    "    image_paths, angles = [], []\n",
    "    for line in lines:\n",
    "        current_path_center = current_path(0,line)\n",
    "        current_path_right = current_path(1,line)\n",
    "        current_path_left = current_path(2,line)\n",
    "        steering_center = float(line[3])\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        correction = 0.15 # this is a parameter to tune\n",
    "        steering_left = steering_center + correction\n",
    "        steering_right = steering_center - correction\n",
    "        image_paths.append(current_path_center)\n",
    "        image_paths.append(current_path_left)\n",
    "        image_paths.append(current_path_right)\n",
    "        angles.append(steering_center)\n",
    "        angles.append(steering_left)\n",
    "        angles.append(steering_right)\n",
    "        \n",
    "    return image_paths, angles\n",
    "\n",
    "#*********************Training Data Generator*************************************************\n",
    "#Reading Data from Training Simulator and adding side camera images\n",
    "def generate_data_training(image_paths, angles, batch_size_generator):\n",
    "    image_paths, angles = shuffle(image_paths, angles)\n",
    "    images,measurements = ([],[])\n",
    "    while True:       \n",
    "        for i in range(len(angles)):\n",
    "            image = cv2.imread(image_paths[i])\n",
    "            angle = angles[i]\n",
    "            image = prepro_image(image)\n",
    "            images.append(image)\n",
    "            measurements.append(angle)\n",
    "            if len(measurements) == batch_size_generator:\n",
    "                yield (np.array(images), np.array(measurements))\n",
    "                images, measurements = ([],[])\n",
    "                image_paths, angles = shuffle(image_paths, angles)\n",
    "            # Data Augmentation: if steering angle is above a certain threshold, the image is flipped horizontally and also added to the training data\n",
    "            if abs(angle) > 0.33:\n",
    "                image = cv2.flip(image, 1)\n",
    "                angle *= -1\n",
    "                images.append(image)\n",
    "                measurements.append(angle)\n",
    "                if len(measurements) == batch_size_generator:\n",
    "                    yield (np.array(images), np.array(measurements))\n",
    "                    images, measurements = ([],[])\n",
    "                    image_paths, angles = shuffle(image_paths, angles)\n",
    "\n",
    "def generate_data_training_visual(image_paths, angles, batch_size_generator):\n",
    "    image_paths, angles = shuffle(image_paths, angles)\n",
    "    images,measurements = ([],[])\n",
    "    while True:       \n",
    "        for i in range(len(angles)):\n",
    "            image = cv2.imread(image_paths[i])\n",
    "            angle = angles[i]\n",
    "            image = prepro_image(image)\n",
    "            images.append(image)\n",
    "            measurements.append(angle)\n",
    "            if len(measurements) == batch_size_generator:\n",
    "                return (np.array(images), np.array(measurements))\n",
    "\n",
    "            # Data Augmentation: if steering angle is above a certain threshold, the image is flipped horizontally and also added to the training data\n",
    "            if abs(angle) > 0.10:\n",
    "                image = cv2.flip(image, 1)\n",
    "                angle *= -1\n",
    "                images.append(image)\n",
    "                measurements.append(angle)\n",
    "                if len(measurements) == batch_size_generator:\n",
    "                    return (np.array(images), np.array(measurements))\n",
    "\n",
    "   \n",
    "#**********Splitting Data in Train/Test*******************\n",
    "image_paths, angles = generate_training_path_sources(lines)\n",
    "image_paths_train, image_paths_test, angles_train, angles_test = train_test_split(image_paths, angles, test_size=0.1, random_state=42)\n",
    "images, measurements = generate_data_training_visual(image_paths,angles,batch_size_generator)\n",
    "\n",
    "size_train=np.array(image_paths_train).shape[0]       \n",
    "size_test=np.array(image_paths_test).shape[0] \n",
    "                                                                           \n",
    "print('Train Dataset size:', np.array(image_paths_train).shape, np.array(angles_train).shape)\n",
    "print('Test Dataset size:', np.array(image_paths_test).shape, np.array(angles_test).shape)\n",
    "print('Image SHAPE:', images[0].shape)\n",
    "\n",
    "\n",
    "#*********************************Visualizing DATA******************************************\n",
    "#display_image(images[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#************************Model*********************************************************\n",
    "Training_Mode=False    \n",
    "if Training_Mode==True:\n",
    "    \n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(lambda x: x / 255.0, input_shape=(66,200,3)))\n",
    "    #model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "    model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "    model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "    model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "    model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "    model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    #************************Training the Model**********************************************\n",
    "    epochs=40\n",
    "    #Compile the Model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "   # initializing Generators\n",
    "    train_data_gen = generate_data_training(image_paths_train, angles_train, batch_size_generator)\n",
    "    val_data_gen = generate_data_training(image_paths_train, angles_train, batch_size_generator)\n",
    "    test_data_gen = generate_data_training(image_paths_test, angles_test, batch_size_generator)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('model{epoch:02d}.h5')\n",
    "\n",
    "    history_object = model.fit_generator(train_data_gen, validation_data=val_data_gen, samples_per_epoch = size_train, nb_epoch = epochs, verbose=1, callbacks=[checkpoint], nb_val_samples=size_train)\n",
    "    \n",
    "    print('Test Loss:', model.evaluate_generator(test_data_gen, batch_size_generator))\n",
    "\n",
    "    print(model.summary())\n",
    "        \n",
    "    model.save('model.h5')\n",
    "    \n",
    "    # Visualizing Predictions\n",
    "    number_predictions = 6\n",
    "    X_test, y_test = generate_data_training_visual(image_paths_test, angles_test, 6)\n",
    "    y_pred = model.predict(X_test, number_predictions, verbose=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #**********************Visualizing the training performance*******************************\n",
    "    ### print the keys contained in the history object\n",
    "    print(history_object.history.keys())\n",
    "    \n",
    "    ### plot the training and validation loss for each epoch\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.plot(history_object.history['val_loss'])\n",
    "    plt.title('model mean squared error loss')\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "    plt.show()    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
